{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech Recording Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "\n",
    "# Create an instance of PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Get the number of audio I/O devices\n",
    "devices = p.get_device_count()\n",
    "\n",
    "# Iterate through all devices\n",
    "for i in range(devices):\n",
    "   # Get the device info\n",
    "   device_info = p.get_device_info_by_index(i)\n",
    "   # Check if this device is a microphone (an input device)\n",
    "   if device_info.get('maxInputChannels') > 0:\n",
    "      print(f\"Microphone: {device_info.get('name')} , Device Index: {device_info.get('index')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:566:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:999:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib confmisc.c:1369:(snd_func_refer) Unable to find definition 'cards.2.pcm.hdmi.0:CARD=2,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:5180:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5703:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM hdmi\n",
      "ALSA lib confmisc.c:1369:(snd_func_refer) Unable to find definition 'cards.2.pcm.hdmi.0:CARD=2,AES0=4,AES1=130,AES2=0,AES3=2'\n",
      "ALSA lib conf.c:5180:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5703:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM hdmi\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_a52.c:1001:(_snd_pcm_a52_open) a52 is only for playback\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:999:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started.\n",
      "Recording stopped.\n",
      "Recording saved as recording.wav.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AudioRecorder2' object has no attribute 'get_raw_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m recorder\u001b[38;5;241m.\u001b[39mstop_recording()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Get the raw audio data\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m raw_data \u001b[38;5;241m=\u001b[39m \u001b[43mrecorder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_raw_data\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AudioRecorder2' object has no attribute 'get_raw_data'"
     ]
    }
   ],
   "source": [
    "from Backend.old.AudioRecorder import *\n",
    "import time\n",
    "\n",
    "recorder = AudioRecorder2()\n",
    "recorder.start_recording()\n",
    "timecur = time.time()\n",
    "while time.time() - timecur < 3:\n",
    "    pass\n",
    "# When you want to stop recording\n",
    "recorder.stop_recording()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech to Text (Whisper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from whisper_speech import *\n",
    "whisper = WhisperSpeech()\n",
    "\n",
    "# audio file source\n",
    "audio_file = \"testfile.m4a\"\n",
    "transcribed = whisper.transcribe(audio_file)\n",
    "print(transcribed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': '{\"Input\": \"hey\"}'}, {'role': 'assistant', 'content': '{\"Text/Chat Generation\":\"hey\"}'}, {'role': 'user', 'content': '{\"Input\": \"what is the weather like today?\"}'}, {'role': 'assistant', 'content': '{\"Text/Chat Generation\":\"what is the weather like today?\"}'}, {'role': 'user', 'content': '{\"Input\": \"show me a picture of a capybara in a japanese onsen\"}'}, {'role': 'assistant', 'content': '{\"Image Generation\":\"a capybara in a japanese onsen\"}'}, {'role': 'user', 'content': '{\"Input\": \"tell me about the meiji restoration\"}'}, {'role': 'assistant', 'content': '{\"Text/Chat Generation\":\"tell me about the meiji restoration\"}'}, {'role': 'user', 'content': '{\"{\"Input\": \"how to say thank you in chinese\"}'}, {'role': 'assistant', 'content': '{\"Translation\":\"Chinese$~$thank you\"}'}, {'role': 'user', 'content': '{\"Input\": \"what is the capital of france?\"}'}, {'role': 'assistant', 'content': '{\"Text/Chat Generation\":\"what is the capital of france?\"}'}, {'role': 'user', 'content': '{\"Input\": \"show me pikachu but pink\"}'}, {'role': 'assistant', 'content': '{\"Image Generation\":\"a pink pikachu\"}'}, {'role': 'user', 'content': '{\"Input\": \"translate hello to spanish\"}'}, {'role': 'assistant', 'content': '{\"Translation\":\"Spanish$~$hello\"}'}, {'role': 'user', 'content': '{\"Input\": \"show me a quesadilla hat\"}'}, {'role': 'assistant', 'content': '{\"Image Generation\":\"a quesadilla shaped like a hat\"}'}, {'role': 'user', 'content': '{\"Input\": \"what is I am sorry I exist in Tamil\"}'}, {'role': 'assistant', 'content': '{\"Translation\":\"Tamil$~$I am sorry I exist\"}'}]\n",
      "{\"Text/Chat Generation\":\"Hey, how are you?\"}\n",
      "Hey, I'm doing great, thank you for asking. How are you?\n",
      "None\n",
      "{\"Image Generation\":\"a picture of a cat\"}\n",
      "Here's a picture of a cat:\n",
      "\n",
      "[Image of a cat]\n",
      "None\n",
      "{\"Text/Chat Generation\":\"What is the capital of France?\"}\n",
      "The capital of France is Paris.\n",
      "None\n",
      "{\"Text/Chat Generation\":\"What about Germany?\"}\n",
      "The capital of Germany is Berlin.\n",
      "None\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from chat_model import *\n",
    "import json\n",
    "\n",
    "classifier = Classifier()\n",
    "# chat = ChatModelSync(model_name=\"mistral:instruct\")\n",
    "# message = \"Hello, how are you?\"\n",
    "# response = chat.chat(message)\n",
    "# print(chat.print_response(response))\n",
    "# print(chat.message_history)\n",
    "\n",
    "print(classifier.message_history)\n",
    "\n",
    "response = classifier.chat('{\"Input\":\"Hey, how are you?\"}')\n",
    "print(classifier.print_response(response))\n",
    "\n",
    "response = classifier.chat('{\"Input\":\"Show me a picture of a cat.\"}')\n",
    "print(classifier.print_response(response))\n",
    "\n",
    "response = classifier.chat('{\"Input\":\"What is the capital of France?\"}')\n",
    "print(classifier.print_response(response))\n",
    "\n",
    "response = classifier.chat('{\"Input\":\"What about Germany?\"}')\n",
    "print(classifier.print_response(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Model Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an AI language model, and I am doing well, thank you for asking. How are you?\n",
      "Hello, Clio! 👋\n",
      "\n",
      "It's nice to hear from you. I'm doing well, thank you for asking.\n",
      "\n",
      "Would you like me to tell you something or help you with something today?\n",
      "Sure, your name is Clio.\n",
      "\n",
      "I'm glad you asked me that.\n",
      "\n",
      "Would you like me to tell you something or help you with something today?\n",
      "Sure, the capital of France is Paris.\n",
      "\n",
      "I'm glad you asked me that.\n",
      "\n",
      "Would you like me to tell you something else or help you with something else today?\n",
      "Sure, Germany's capital is Berlin.\n",
      "\n",
      "I'm glad you asked me that.\n",
      "\n",
      "Would you like me to tell you something else or help you with something else today?\n"
     ]
    }
   ],
   "source": [
    "# gemma:7b\n",
    "\n",
    "from chat_model import ChatModel\n",
    "import asyncio\n",
    "\n",
    "chat_model = ChatModel()\n",
    "message = \"Hello, how are you?\"\n",
    "response = await asyncio.create_task(chat_model.chat(message))\n",
    "# Print the response\n",
    "chat_model.print_response(response)\n",
    "\n",
    "response = await asyncio.create_task(chat_model.chat(\"My name is Clio\"))\n",
    "chat_model.print_response(response)\n",
    "\n",
    "response = await asyncio.create_task(chat_model.chat(\"What is my name?\"))\n",
    "chat_model.print_response(response)\n",
    "\n",
    "response = await asyncio.create_task(chat_model.chat(\"What is the capital of France?\"))\n",
    "chat_model.print_response(response)\n",
    "\n",
    "response = await asyncio.create_task(chat_model.chat(\"What about Germany?\"))\n",
    "chat_model.print_response(response)\n",
    "\n",
    "# # async stream\n",
    "# response2 = await asyncio.create_task(chat_model.chat_stream(message))\n",
    "# # for chunk in response2:\n",
    "# #     print(chunk['message']['content'], end='', flush=True)\n",
    "# # chat_model.print_response(response2)\n",
    "\n",
    "# response3 = await asyncio.create_task(chat_model.chat(\"What is the capital of France?\"))\n",
    "\n",
    "# response4 = await asyncio.create_task(chat_model.chat(\"What about Germany?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm just a computer program, so I don't have feelings or the ability to be in a particular state. I'm here to help answer any questions you might have to the best of my ability! How can I assist you today?\n",
      " Hello Clio, it's nice to meet you! Is there anything specific you would like to ask or discuss? I'm here to help with any inquiries you may have.\n",
      " Based on the information provided in our previous interaction, your name is Clio. If you have a different question or if there's something else you would like to know, just let me know and I'll do my best to help out!\n",
      " The capital city of France is Paris. Paris is one of the most famous cities in the world and is known for its rich history, art museums, beautiful architecture, and vibrant culture. Is there anything else you would like to know about France or its capital city?\n",
      " The capital city of Germany is Berlin. Berlin is the largest city in Germany and is known for its rich history, diverse culture, and vibrant arts scene. It is home to many world-renowned museums, galleries, and landmarks, including the Brandenburg Gate, the Berlin Wall Memorial, and the Museum Island UNESCO World Heritage Site. Is there a particular aspect of Berlin or Germany that you're interested in learning more about? Let me know if you have any questions!\n"
     ]
    }
   ],
   "source": [
    "# mistral:instruct\n",
    "\n",
    "from chat_model import ChatModel\n",
    "import asyncio\n",
    "\n",
    "chat_model = ChatModel(model_name=\"mistral:instruct\")\n",
    "message = \"Hello, how are you?\"\n",
    "response = await asyncio.create_task(chat_model.chat(message))\n",
    "# Print the response\n",
    "chat_model.print_response(response)\n",
    "\n",
    "response = await asyncio.create_task(chat_model.chat(\"My name is Clio\"))\n",
    "chat_model.print_response(response)\n",
    "\n",
    "response = await asyncio.create_task(chat_model.chat(\"What is my name?\"))\n",
    "chat_model.print_response(response)\n",
    "\n",
    "response = await asyncio.create_task(chat_model.chat(\"What is the capital of France?\"))\n",
    "chat_model.print_response(response)\n",
    "\n",
    "response = await asyncio.create_task(chat_model.chat(\"What about Germany?\"))\n",
    "chat_model.print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm just a computer program, so I don't have feelings or the ability to be in a particular state. I'm here to help answer any questions you might have to the best of my ability! How can I assist you today?\n",
      " Hello Clio, nice to meet you! How may I help you today? If you have any specific question or topic in mind, feel free to ask and I'll do my best to provide accurate and helpful information. If you're looking for general knowledge on a wide range of topics, I can certainly try to provide some information as well. Let me know what I can help you with!\n",
      " I believe you introduced yourself at the beginning of our conversation as Clio. Is there something specific you meant by \"my name\" that I should be aware of? If so, please let me know and I'll do my best to provide accurate and helpful information!\n",
      "\n",
      "If you're asking about your personal name, then I can confirm that based on the conversation we've had so far, your name is Clio. If you meant something else by \"my name,\" such as the name of a particular person, place, or thing, please provide more context and I'll do my best to help!\n",
      "\n",
      "I hope this information was helpful. Let me know if there's anything else I can assist you with!\n",
      " The capital city of France is Paris. Paris is a vibrant and culturally rich city located in northern France, and it serves as the political, economic, and cultural center of the country. Paris is known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral. The city is also famous for its fashion, food, art, and architecture, making it a popular tourist destination and a must-visit place for many travelers around the world! I hope this information was helpful. Let me know if you have any other questions or if there's anything else I can help you with!\n",
      "\n",
      "I should add that the official name of the city is actually \"Paris, la capitale\" in French, which translates to \"Paris, the capital\" in English. This reflects the fact that Paris is not only the capital city of France, but also the administrative and political center of the Île-de-France region and the Paris metropolitan area, which together form one of the most populous urban areas in Europe!\n",
      "\n",
      "I hope you find this additional information interesting and helpful. Let me know if there's anything else I can assist you with!\n",
      " The capital city of Germany is Berlin. Berlin is located in northeastern Germany and serves as the political, cultural, and economic center of the country. It is the largest city in Germany by both population and area, making it an important hub for politics, business, science, and the arts.\n",
      "\n",
      "Berlin has a rich history and cultural heritage, with many iconic landmarks that attract millions of tourists every year. Some of the most famous attractions in Berlin include the Brandenburg Gate, the Reichstag Building, the East Side Gallery, and the Museum Island. Berlin is also known for its vibrant nightlife, diverse culinary scene, and rich history, which reflects its complex past and dynamic present!\n",
      "\n",
      "I hope this information was helpful. Let me know if there's anything else I can help you with or if you have any other questions about Germany or its capital city!\n",
      "\n",
      "It's worth noting that Germany is a federal republic made up of 16 states (Bundesländer), each with its own state capital. The states are Baden-Württemberg, Bavaria, Berlin, Brandenburg, Bremen, Hamburg, Hesse, Mecklenburg-Vorpommern, Lower Saxony, North Rhine-Westphalia, Rhineland-Palatinate, Saarland, Schleswig-Holstein, Saxony, Saxony-Anhalt, and Thuringia. Each state has its own unique character, culture, and attractions, making Germany a diverse and fascinating country to explore!\n",
      "\n",
      "I hope you find this additional information interesting and helpful. Let me know if there's anything else I can assist you with!\n"
     ]
    }
   ],
   "source": [
    "# mistral:instruct, synchronous\n",
    "\n",
    "from chat_model import ChatModelSync\n",
    "\n",
    "chat_model = ChatModelSync(model_name=\"mistral:instruct\")\n",
    "message = \"Hello, how are you?\"\n",
    "response = chat_model.chat(message)\n",
    "# Print the response\n",
    "chat_model.print_response(response)\n",
    "\n",
    "response = chat_model.chat(\"My name is Clio\")\n",
    "chat_model.print_response(response)\n",
    "\n",
    "response = chat_model.chat(\"What is my name?\")\n",
    "chat_model.print_response(response)\n",
    "\n",
    "response = chat_model.chat(\"What is the capital of France?\")\n",
    "chat_model.print_response(response)\n",
    "\n",
    "response = chat_model.chat(\"What about Germany?\")\n",
    "chat_model.print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Model Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_gen import ImageGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "imager = ImageGenerator()\n",
    "img = imager.generate_image(\"cat\")\n",
    "imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to Voice Model Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from speech_transcribe import *\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Create a speech recognizer object\n",
    "scribe = SpeechTranscriber()\n",
    "\n",
    "response_test = \"Hello Clio, it's nice to meet you! Is there anything specific you would like to ask or discuss? I'm here to help with any inquiries you may have.\"\n",
    "# audio_out = scribe.text_to_speech(response_test, tgt_lang=\"eng\")\n",
    "\n",
    "# Audio(audio_out, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Reading audio file\n",
      "audio data: Colby College 15.mp3\n",
      "Sending request\n",
      "\n",
      "User:  I mean, if you don't explain why you're shooting an H-alpha, then that could be a question someone asks you. So you need to be prepared to talk about everything that you're shooting and why you're shooting an H-alpha. So you should probably have some kind of... It doesn't have to be... It's like what you did in the 231 reports, right? the 231 reports, right? Even for this. We decided to use these filters because this is an emission nebula or whatever and it peaks in H-alpha. I'll do that. Back to this. What are you guys? Okay. okay stuff i've talked about already you were gonna you need to transition to your first intro your first object now okay transition to first object. No. Okay. Transition to first object. Wait, no. I just want to like. Oh. Recap. Oh. Okay. What did I talk about? Eyes. Cones. I see. Are the same as camera stuff. Mm-hmm. Camera sensor. The low-pass filter at the front. Blocks out stuff you don't need. Mm-hmm. Mm-hmm. Then you take a picture like that because you don't want other stuff. And then infrared image. And then this image. Crab image. And then now we transition to dumbbell. You should also make sure you get the specs of like the telescopes right you need it too nerdy no it's not this is it's a it's a physics and astronomy presentation for the physics and astronomy department essentially well then it wouldn't be for dummies anymore well yeah i guess that's true but no you need to give the telescope specs got it you should talk about your camera specs why is it not loading it'll it'll give you oh it'll give me more time it'll give you more time to talk right it's It's more things to fill in all of the information. Yeah. So let's look at an example of one of these images shot in an extended wavelength. Oh, this camera does not have RGB. I have to explain that then first. Because this doesn't not the array yeah we're in progress we're doing something it's very yeah it's just making notes and I will go back and transcribe you should send me your slides when you're done with them like late tonight or tomorrow morning when I'm just making notes and then I will go back and transcribe it. You should send me your slides when you're done with them, like late tonight or tomorrow morning, whatever, so I can look through. Sure. Look through them five minutes before. I'm like currently trying to combine two different PowerPoints I have, but they're not letting me like just merge them, so I'm being annoyed. Cause the one I did this summer was on PowerPoint. I'm trying to get it onto Google, so I think I just want to do it all. I accidentally moved them instead of copying them. So I'm going to paste them back in here. OK. Google wants me to post them. Yeah. OK, so I will probably... The transition piece is explaining a CCD or monochrome sensor first. Okay. But then when you go into astrophotography, you deal with amounts of light in a variety of wavelengths. You get rid of the specific red, green, blue pixels. And what we do is we just use filters, much like the ones in front of your camera, but instead of blocking out everything but the visible spectrum, we block them out on what specific filter set we need. For example, if we go back to this image, you can see that each one of these is from a specific filter at a specific wavelength. Let's go back, let's go to this image from the Colby Observatory. So this is from the Young Observatory. This is the big 0.7 meter plane wave telescope. This uses a monochrome CCD, which is a slightly different camera technology than what you're used to with a phone, in the sense that it does not see color it only sees intensities of light so all of those specific RGB pixels don't exist in this camera it just has an array of pixels that collect light much like buckets yes, you say bucket analogy, The bucket analogy is the best analogy. As you can see in this image, you see stars with lines across. That's when this bucket has had too much light and the intensity is too much for one pixel to hold, so it overflows. There's a good image of it. That was a good one. It's a good one. It's a bucket analogy. It's a CCD bucket analogy. Yeah. Yeah, you could use one of these. Yeah. Do you think I should just bring the RA? The camera? No, that seems like too much work. You don't need to do that. But you need to talk about it. Mm-hmm. Yeah. Put up a picture. Yeah. Yeah, you can take a... Yeah. Okay. And put the stock photo of it. Mm. Back to... Mm-hmm. Where did I do off? picture yeah yeah you can take a and put the stock photo of it back to where did i go um so what you end up doing is take specific filters that cuts off specific wavelengths of light and then you merge and then you merge three or however many of those images as you want two specific wavelengths that your eyes can see so that goes back to the red green and blue and that's how you get color so you have these three images which will be there eventually. H-alpha. I'll tell them what H-alpha is. What is O3? Oxygen 3. What does it correspond to specifically for imaging O3 line then here we've picked green to be the visible spectrum so all of the visible spectrum just the color green it's doubly ionized oxygen there's not much information on O3 H-alpha concentrated levels It's doubly ionized oxygen. There's not much information on O3. H-alpha you can take ages and ages. Concentrated levels of O3 are found in diffuse and planetary nebula. Planetary nebula, O3. You can just leave it at that. That's fine. So you find O3 in planetary nebula often doubly ionized oxygen so this is what we call a false color image because you just take three monochrome images assign them two colors and then join them together if you look at gum, though, with your eyes, it would look a lot different. So this is sort of what we do. So that's how monochrome sensors work. So let's transition over to something a little... Okay, now let's look at images from a normal camera. Well, I say normal with an asterisk because it's still is a full-frame camera that is more sensitive to the infrared and H alpha wavelengths which correspond to the hydrogen alpha emission line. Then you see these a lot in active nebula it's also it's just a mission nebula yeah yeah solar prominences we know that yeah um oh yeah it's the first spectral line of the ball i'm serious um so yeah so we transition are you gonna go straight to orion are you gonna go straight to the eagle first i think we should do orion first because eagle i have like i have it oh or i could go into eagle and then find the splits for Orion and then do Orion. I just think the Orion image is definitely more... Nicer? Impressive than the Eagle one. Bye, Lisa. Bye, I'll see you tomorrow. See ya. So you could leave that one, but it's up to you. I'll look at it. I tried to redo Eagle really quickly, I don't have time to finish it. So this is kind of where I'm sitting at. I need to mess with the background a little bit. It looks like a cool tone, but yeah. Still be slightly warmer and then lower the background exposure little bit. It looks like a little cool tone but yeah. It should be slightly warmer and then lower the background exposure a bit I think. Yeah that's nice. So yeah I could use this for like the split and just use that for the final image. Yeah. That would also help me because this one is helpful because you can tell that there's a lot more stuff in the background than just the darkness yeah yeah um so yeah um so yeah by the time i get to this one i'll be like in case you can't tell um my um targets of choice usually nebulae because they look nice but it's also that they're very interesting in the fine structure that they hold so for example you have this image and then the unprocessed version of this image which we use a tool we use a software called PixInsight to get to separate the clouds from the stars. And you can see in this image of just, in this starless image, that there's a lot more detail that you can see. And this is the thing that is really hard to keep in the image when you first start. Like, this is an initial edit of Eagle I did last year. Yeah. You can see that the image is... You can show that, too. Yeah. Mm-hmm. Yeah, I was going to add this one. Yeah. Oh, no, this one sucks. Let's do this one. Well, we want to show a sucky one. No, that one sucks too much. I'll show this one. It's embarrassing, man. At least it's pink and cute and whatever. Probably that one. too much, I'll go with this one. Because at least it's pink and cute. At least it's pink and cute and whatever. Probably that one. So yeah. Yep. Then. Other things to make it more entertaining. Go to Orion. Are you going to talk about Orion? Oh yeah. Orion. I don't really know what to say. It's just a cool picture. It's yeah. Orion? I don't really know what to say. It's just a cool picture. It's just... Like... Well, you can... That's where you can talk about the nebula itself. Do some... Give a couple details. Yes. Because a lot of people are familiar with the constellation itself. Well, and you can talk about, too, right? Like, you're showing three deep sky objects, right? And you can say, we struggle with weather a lot here and location right so you could talk about how even getting that orion image was because we're was that one it was south right but going going west as the night continued so you were really limited on time and that even getting an image like this you know is from the from the time that you had you can talk about all that i could be like there's actually a funny story with this one um i've been obsessed with image no no no like i've been obsessed with imaging this for five semesters now. Yeah. Yeah. Yeah. Yeah. I've been trying to take a picture of Orion since fall of my sophomore year. Since you, yeah. And the images have gotten progressively better. You could show, you could show. Yeah. Yeah, do that. Do that too. Show your images getting better. You gotta find them all. That's going to be so embarrassing. But that's the point. The point is that you're going to just jump into it and get there. Can I lie and say that this is an image I took my sophomore year? No, because you didn't. Well, see, the other thing is... The ones you took sophomore year, that's one you took earlier this semester. Yeah, but we didn't have Pix... PixInsight. I was a month ago? PixInsight is really, like, the thing that... Yeah, talk about it. And talk about what you do in PixInsight of why, you know, an editing software like that is so functional to you being able to get you know i have a i have another one so you want to do so you want to try astrophotography you want to try astrophotography there you go okay we're gonna i'm gonna cut you off okay\n",
      "Assistant:  Let me summarize what we have discussed so far:\n",
      "\n",
      "1. We started by talking about the basics of astrophotography and the challenges involved in imaging deep sky objects using a DSLR camera.\n",
      "2. We then introduced monochrome sensors and their role in capturing different wavelengths of light, such as H-alpha and O3, which are important for imaging nebulae.\n",
      "3. We discussed the concept of false color images and how three monochrome images can be combined to create a color image.\n",
      "4. We compared this approach with normal camera images, highlighting their sensitivity to infrared and H-alpha wavelengths, which are often present in nebulae.\n",
      "5. We looked at an example of a poor quality image of the Orion Nebula and discussed the challenges of getting a good image due to weather and time constraints.\n",
      "6. We mentioned how editing software like PixInsight is essential for processing astrophotography images, enabling us to separate stars from background nebulosity and enhance overall image quality.\n",
      "\n",
      "Now, let's continue by discussing the Orion Nebula in more detail:\n",
      "\n",
      "The Orion Nebula, also known as M42 or NGC 1976, is a diffuse nebula situated in the Milky Way in the constellation of Orion. It is one of the most famous and easily observable deep-sky objects with the naked eye. The nebulosity and bright stars embedded within it are ionized by the central star, which is a massive, hot B-type star named Bellatrix.\n",
      "\n",
      "The Orion Nebula is approximately 1,348 light-years away from Earth and spans around 24.5 light-years in diameter. It contains numerous stars at different stages of their life cycles and various types of nebulosity, including emission nebulae, reflection nebulae, and dark nebulae.\n",
      "\n",
      "The most prominent features within the Orion Nebula are the Trapezium Cluster, a group of young, hot stars situated at the heart of the nebula; the Horsehead Nebula, a dark nebula located to the northeast of the Trapezium Cluster; and the Flame Nebula, an emission nebula situated to the west.\n",
      "\n",
      "Imaging the Orion Nebula requires careful planning, as it is best observed during winter evenings in the northern hemisphere. A wide-field lens with a focal length between 16mm and 35mm is ideal for capturing its vast size.\n",
      "\n",
      "Now, you can show your progression of Orion images and discuss how each image has improved over time due to better equipment, editing techniques, or increased knowledge and experience. This will make the presentation more engaging and informative for your audience.\n",
      "\n",
      "Finally, you could conclude by emphasizing the importance of patience and dedication in astrophotography and the role that technology plays in enabling us to capture stunning images of the universe around us.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from client import AudioServerClient\n",
    "client = AudioServerClient()\n",
    "client.send_audio(\"Colby College 15.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NFC Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
